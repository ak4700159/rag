from langchain_recommender import LangchainRecommender
from config import DEFAULT_IMAGE_PATH, DEFAULT_PDF_PATH
import os

# ê²½ë¡œ ì„¤ì •
IMAGES_PATH = os.path.join(os.path.dirname(__file__), "ImagesPath")
DEFAULT_IMAGE_PATH = os.path.join(IMAGES_PATH, "land.jpg")

def chat_with_gpt(recommender, user_input):
    """GPTì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜"""
    try:
        response = recommender.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ì§„ ì´¬ì˜ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": user_input
                }
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def main():
    # ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    recommender = LangchainRecommender()

    print("\n=== ì´ë¯¸ì§€ ì‚¬ì§„ ë¶„ì„ ì‹œìŠ¤í…œ ===")
    print("ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")

    # PDF ì²˜ë¦¬ í™•ì¸
    if not os.path.exists(DEFAULT_PDF_PATH):
        print(f"ê¸°ë³¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DEFAULT_PDF_PATH}")
        print("PDF íŒŒì¼ì„ ë¨¼ì € ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        return

    print("\nPDF ì²˜ë¦¬ ì¤‘...")
    if recommender.process_pdf(DEFAULT_PDF_PATH):
        print("PDF ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("PDF ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    """í”½í† ë¦¬ (Pictory) â†’ Picture + History / Story"""
    print("\nì•ˆë…•í•˜ì„¸ìš”ğŸ¤š ì €ëŠ” AI í”½í† ë¦¬ ì…ë‹ˆë‹¤ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?.ğŸ˜Š")

    print("\n")
    print("í”½í† ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:")
    print("1. ì‚¬ì§„ í‰ê°€ê°€ í•„ìš” í•˜ì‹œë©´ ('í‰ê°€í•´ì¤˜'ë¼ê³  ì…ë ¥í•˜ì„¸ìš”)")
    print("2. ì‚¬ì§„ ë¹„êµê°€ í•„ìš” í•˜ì‹œë©´ ('ë¹„êµí•´ì¤˜'ë¼ê³  ì…ë ¥í•˜ì„¸ìš”")
    print("3. íŠ¹ì • ì§€ì—­ ì‚¬ì§„ ê²€ìƒ‰ í•´ì¤˜ ('ì§€ì—­ê²€ìƒ‰'ë¼ê³  ì…ë ¥í•˜ì„¸ìš”")
    print("4. ì£¼ë³€ ì‚¬ì§„ ê²€ìƒ‰ í•´ì¤˜ ('ì£¼ë³€ê²€ìƒ‰'ë¼ê³  ì…ë ¥í•˜ì„¸ìš”")
    print("4. í”„ë¡œê·¸ë¨ ì¢…ë£Œ ('ì¢…ë£Œ ë¼ê³  ì…ë ¥ í•˜ì‹œë©´ ì¢…ë£Œ ë©ë‹ˆë‹¤.')")

    while True:
        user_input = input("\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ").strip()

        if user_input.lower() in ['ì¢…ë£Œ', 'quit']:
            print("\n PICTO ì–´í”Œì´ ë§Œì¡±ìŠ¤ëŸ¬ìš°ì…¨ë‚˜ìš”? ë‹¤ìŒì—ë„ ì´ìš© ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤ğŸ–ï¸.")
            break

        if "í‰ê°€í•´ì¤˜" in user_input:
            print(f"\nê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ: {DEFAULT_IMAGE_PATH}")
            image_path = input("ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—”í„°ì‹œ ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©): ").strip()

            if not image_path:
                image_path = DEFAULT_IMAGE_PATH

            if not os.path.exists(image_path):
                print("ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

            print("\nì´ë¯¸ì§€ ë¶„ì„ ë° ì¶”ì²œ ì¤‘...")
            result = recommender.process_user_request(user_input, image_path)

            if result.get("ìƒíƒœ") == "ì˜¤ë¥˜":
                print(f"\nì˜¤ë¥˜: {result['ë©”ì‹œì§€']}")
            elif result.get("ìƒíƒœ") == "ì•ˆë‚´":
                print(f"\nì•ˆë‚´: {result['ë©”ì‹œì§€']}")
            else:
                print("\n=== ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ===")
                print(result["ì´ë¯¸ì§€ ë¶„ì„"])
                print("\n=== ì´¬ì˜ ê°€ì´ë“œë¼ì¸ ===")
                print(result["ì´¬ì˜ ê°€ì´ë“œë¼ì¸"])

        else:
            # GPTì™€ ëŒ€í™”
            print("\nGPT ì‘ë‹µ ìƒì„± ì¤‘...")
            response = chat_with_gpt(recommender, user_input)
            print("\nGPT ì‘ë‹µ:")
            print(response)

if __name__ == "__main__":
    main()